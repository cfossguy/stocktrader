{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Allstate (ALL), the recent news summary indicates positive developments over the past three months. The company reported strong Q2 2024 earnings, exceeding analyst estimates with revenues of $15.82 billion and an EPS of $1.61. Following these announcements, the stock surged by 5%. Additionally, a notable $2 billion sale of its employer voluntary-benefits business aligns with Allstate's strategic focus on core insurance operations. Analysts have been optimistic, averaging a price target of $187.33. Overall, Allstate is regarded as a strong investment with high potential for growth due to improved premiums and strategic acquisitions, and recommendation sentiment is categorized as a \"buy\" [context].\n"
     ]
    }
   ],
   "source": [
    "## Install the required packages\n",
    "## pip install -qU elasticsearch openai\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    hosts=os.environ[\"ELASTIC_SEARCH_URL\"],\n",
    "    api_key=os.environ[\"ES_API_KEY\"]\n",
    ")\n",
    "      \n",
    "openai_client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "index_source_fields = {\n",
    "    \"ticker_watchlist\": [\n",
    "        \"context_flattened\"\n",
    "    ]\n",
    "}\n",
    "def get_elasticsearch_results(query):\n",
    "    es_query = {\n",
    "        \"retriever\": {\n",
    "            \"rrf\": {\n",
    "                \"retrievers\": [\n",
    "                    {\n",
    "                        \"standard\": {\n",
    "                            \"query\": {\n",
    "                                \"sparse_vector\": {\n",
    "                                    \"field\": \"fundamental_summary_embedding\",\n",
    "                                    \"inference_id\": \".elser_model_2_linux-x86_64\",\n",
    "                                    \"query\": query\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"standard\": {\n",
    "                            \"query\": {\n",
    "                                \"sparse_vector\": {\n",
    "                                    \"field\": \"news_summary_embedding\",\n",
    "                                    \"inference_id\": \".elser_model_2_linux-x86_64\",\n",
    "                                    \"query\": query\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"standard\": {\n",
    "                            \"query\": {\n",
    "                                \"sparse_vector\": {\n",
    "                                    \"field\": \"technical_summary_embedding\",\n",
    "                                    \"inference_id\": \".elser_model_2_linux-x86_64\",\n",
    "                                    \"query\": query\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    result = es_client.search(index=\"ticker_watchlist\", body=es_query)\n",
    "    return result[\"hits\"][\"hits\"]\n",
    "def create_openai_prompt(question, results):\n",
    "    context = \"\"\n",
    "    for hit in results:\n",
    "        inner_hit_path = f\"{hit['_index']}.{index_source_fields.get(hit['_index'])[0]}\"\n",
    "        ## For semantic_text matches, we need to extract the text from the inner_hits\n",
    "        if 'inner_hits' in hit and inner_hit_path in hit['inner_hits']:\n",
    "            context += '\\n --- \\n'.join(inner_hit['_source']['text'] for inner_hit in hit['inner_hits'][inner_hit_path]['hits']['hits'])\n",
    "        else:\n",
    "            source_field = index_source_fields.get(hit[\"_index\"])[0]\n",
    "            hit_context = hit[\"_source\"][source_field]\n",
    "            context += f\"{hit_context}\\n\"\n",
    "    prompt = f\"\"\"\n",
    "  Instructions:\n",
    "  \n",
    "  - You are an assistant for question-answering tasks. Please customize your responses for a stock picker analyst user.\n",
    "  - Answer questions truthfully and factually using only the context presented.\n",
    "  - If you don't know the answer, just say that you don't know, don't make up an answer.\n",
    "  - You must always cite the document where the answer was extracted using inline academic citation style [], using the position.\n",
    "  - Use markdown format for code examples.\n",
    "  - You are correct, factual, precise, and reliable.\n",
    "  \n",
    "  Context:\n",
    "  {context}\n",
    "  \n",
    "  \"\"\"\n",
    "    return prompt\n",
    "def generate_openai_completion(user_prompt, question):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": user_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"What is the news summary for ALL?\"\n",
    "    elasticsearch_results = get_elasticsearch_results(question)\n",
    "    context_prompt = create_openai_prompt(question, elasticsearch_results)\n",
    "    openai_completion = generate_openai_completion(context_prompt, question)\n",
    "    print(openai_completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockpicker-z85df5Gi-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
